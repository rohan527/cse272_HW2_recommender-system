# -*- coding: utf-8 -*-
"""HW2 - Recommendation System.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Q4qRxWJO8EwhQGhS4MUhAGZSNjMhSSmf

# Recommendation System

##Installing Surprise and mounting Drive
"""

!pip install surprise

from google.colab import drive
drive.mount('/content/drive')

"""## Libraries

Here we are first going to import all the nescessary libraries. We will also import our dataset for the recommendation system. I decided to use the **Automotive dataset**. 
"""

from surprise import KNNWithMeans
from surprise import prediction_algorithms
from surprise import Dataset
from surprise import accuracy
from surprise import Reader
from surprise.model_selection import train_test_split
from surprise.model_selection import KFold
from surprise import CoClustering
from surprise import SVD
from surprise import SlopeOne

import os
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split as tts
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from math import sqrt
from collections import defaultdict

"""## Data Preprocessing

### Selecting first million datapoints

Colab keeps crashing when I try to import the entire json file. Here, I am only selecting the first million entries from the dataset. This dataset I am then converting to a csv file which I use for splitting into training and testing datatset.
"""

#df = pd.read_json('/content/drive/MyDrive/Automotive.json', lines = True, nrows=1000000)

#df.drop(['verified', 'reviewTime', 'style', 'reviewerName', 'summary', 'unixReviewTime', 'vote', 'image'], axis=1, inplace=True)

#df.to_csv('/content/drive/MyDrive/23 - Spring Quarter/CSE 272 - IR/HW 2/dataset.csv', index=False)

"""### Splitting the data"""

dataset = pd.read_csv('/content/drive/MyDrive/23 - Spring Quarter/CSE 272 - IR/HW 2/dataset.csv')

dataset.info()

dataset = dataset[['reviewerID','asin', 'overall']]

dataset.info()

reader = Reader(rating_scale=(1, 5))

dataset = Dataset.load_from_df(dataset, reader)

trainset, testset = train_test_split(dataset, test_size=0.2, random_state=10)

"""## Co-Clustering

Co-Clustering is a collaborative filtering algorithm that simultaneously clusters users and items based on their rating patterns. It identifies groups of users and items that share similar rating behaviors. 
"""

coclustering = CoClustering(n_cltr_u=3, n_cltr_i=3, n_epochs=10)

coclustering.fit(trainset)

test_predictions_coclustering = coclustering.test(testset)

rmse_coclusterting = accuracy.rmse(test_predictions_coclustering)

mae_coclusterting = accuracy.mae(test_predictions_coclustering)

print("The RMSE and MAE values for coclustering are:")
print("RMSE - " + str(rmse_coclusterting))
print("MAE - " + str(mae_coclusterting))

"""## Collaborative Filtering - Item Based Recommendation

SVD is a matrix factorization-based algorithm that decomposes the user-item rating matrix into low-rank matrices to capture latent factors. To use SVD in Surprise, you can create an instance of the SVD class and customize its parameters as needed. 
"""

svd = SVD(n_factors=100, n_epochs=20, biased=True)

svd.fit(trainset)

test_predictions_CF = svd.test(testset)

rmse_CF = accuracy.rmse(test_predictions_CF)

mae_CF = accuracy.mae(test_predictions_CF)

print("The RMSE and MAE values for Collaborative Filtering are:")
print("RMSE - " + str(rmse_CF))
print("MAE - " + str(mae_CF))

"""## SlopeOne

Slope One is a simple but effective collaborative filtering algorithm that calculates the average difference in ratings between items and uses this information to make predictions.
"""

slope_one = SlopeOne()

slope_one.fit(trainset)

test_predictions_Slope = slope_one.test(testset)

rmse_slope = accuracy.rmse(test_predictions_Slope)

mae_slope = accuracy.mae(test_predictions_Slope)

print("The RMSE and MAE values for Slope One are:")
print("RMSE - " + str(rmse_slope))
print("MAE - " + str(mae_slope))

"""##Ranking

Here we create a ranking function for getting the top 10 recommendation for each of the algorithms.
"""

def get_top_n(predictions, n=10):
    """Return the top-N recommendation for each user from a set of predictions.

    Args:
        predictions(list of Prediction objects): The list of predictions, as
            returned by the test method of an algorithm.
        n(int): The number of recommendation to output for each user. Default
            is 10.

    Returns:
    A dict where keys are user (raw) ids and values are lists of tuples:
        [(raw item id, rating estimation), ...] of size n.
    """

    # First map the predictions to each user.
    top_n = defaultdict(list)
    for uid, iid, true_r, est, _ in predictions:
        top_n[uid].append((iid, est))

    # Then sort the predictions for each user and retrieve the k highest ones.
    for uid, user_ratings in top_n.items():
        user_ratings.sort(key=lambda x: x[1], reverse=True)
        top_n[uid] = user_ratings[:n]

    return top_n

"""###CoClustering"""

top_10_coclustering = get_top_n(test_predictions_coclustering, n=10)

top_10_coclustering

"""###Collaborative Filtering"""

top_10_CF = get_top_n(test_predictions_CF, n=10)

top_10_CF

"""###SlopeOne"""

top_10_slope = get_top_n(test_predictions_Slope, n=10)

top_10_slope

"""###Precision and Recall

Here we create a function to calculate the precision and recall for the algorithms. The precision and recall function can be found in [surprise documentation](https://surprise.readthedocs.io/en/stable/FAQ.html). 
"""

def precision_recall_at_k(predictions, k=10, threshold=3.5):
    """Return precision and recall at k metrics for each user"""

    # First map the predictions to each user.
    user_est_true = defaultdict(list)
    for uid, _, true_r, est, _ in predictions:
        user_est_true[uid].append((est, true_r))

    precisions = dict()
    recalls = dict()
    for uid, user_ratings in user_est_true.items():

        # Sort user ratings by estimated value
        user_ratings.sort(key=lambda x: x[0], reverse=True)

        # Number of relevant items
        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)

        # Number of recommended items in top k
        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])

        # Number of relevant and recommended items in top k
        n_rel_and_rec_k = sum(
            ((true_r >= threshold) and (est >= threshold))
            for (est, true_r) in user_ratings[:k]
        )

        # Precision@K: Proportion of recommended items that are relevant
        # When n_rec_k is 0, Precision is undefined. We here set it to 0.

        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0

        # Recall@K: Proportion of relevant items that are recommended
        # When n_rel is 0, Recall is undefined. We here set it to 0.

        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 0

    return precisions, recalls

precisions, recalls = precision_recall_at_k(test_predictions_CF, k=5, threshold=4)

    # Precision and recall can then be averaged over all users

prec_CF = sum(prec for prec in precisions.values()) / len(precisions)

rec_CF = sum(rec for rec in recalls.values()) / len(recalls)

fmeasure_CF = (2*prec_CF*rec_CF)/(prec_CF+rec_CF)

print("The precision, recall and f-measure values for Collaborative Filtering are: ")
print("Precision: "+ str(prec_CF))
print("Recall: "+ str(rec_CF))
print("F-Measure: "+ str(fmeasure_CF))

precisions1, recalls1 = precision_recall_at_k(test_predictions_Slope, k=5, threshold=4)

    # Precision and recall can then be averaged over all users

prec_slope = sum(prec for prec in precisions1.values()) / len(precisions1)

rec1_slope = sum(rec for rec in recalls1.values()) / len(recalls1)

fmeasure_slope = (2*prec_slope*rec1_slope)/(prec_slope+rec1_slope)

print("The precision, recall and f-measure values for Slope One are: ")
print("Precision: "+ str(prec_slope))
print("Recall: "+ str(rec1_slope))
print("F-Measure: "+ str(fmeasure_slope))

precisions2, recall2 = precision_recall_at_k(test_predictions_coclustering, k=5, threshold=4)


prec_CC = sum(prec for prec in precisions2.values()) / len(precisions2)

rec_CC = sum(rec for rec in recall2.values()) / len(recall2)

fmeasure_CC = (2*prec_CC*rec_CC)/(prec_CC+rec_CC)

print("The precision, recall and f-measure values for Co-clustering are: ")
print("Precision: "+ str(prec_CC))
print("Recall: "+ str(rec_CC))
print("F-Measure: "+ str(fmeasure_CC))

"""##Final Results 

Here we simply print the final results. 
"""

print("The final results for the Co-clustering are: ")
print("RMSE - " + str(rmse_coclusterting))
print("MAE - " + str(mae_coclusterting))
print("Precision - "+ str(prec_CC))
print("Recall - "+ str(rec_CC))
print("F-Measure - "+ str(fmeasure_CC))
print()
print("The final results for the Collaborative Filtering are: ")
print("RMSE - " + str(rmse_CF))
print("MAE - " + str(mae_CF))
print("Precision - "+ str(prec_CF))
print("Recall - "+ str(rec_CF))
print("F-Measure - "+ str(fmeasure_CF))
print()
print("The final results for the Slope One are: ")
print("RMSE - " + str(rmse_slope))
print("MAE - " + str(mae_slope))
print("Precision - "+ str(prec_slope))
print("Recall - "+ str(rec1_slope))
print("F-Measure - "+ str(fmeasure_slope))